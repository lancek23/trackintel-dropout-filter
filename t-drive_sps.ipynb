{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0fc3a09",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackintel as ti\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from trackintel.preprocessing import generate_staypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd40779",
   "metadata": {},
   "source": [
    "User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timezone = 'Asia/Shanghai'\n",
    "\n",
    "data_path = 'release/taxi_log_2008_by_id/'\n",
    "\n",
    "# Set dropout threshold (should match min staypoint duration)\n",
    "dropout_threshold = pd.Timedelta(minutes=10)\n",
    "# Set time difference threshold between dropout/staypoint start here\n",
    "diff_threshold = pd.Timedelta(minutes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29463ec3",
   "metadata": {},
   "source": [
    "Generate initial staypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58269bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(data_path+'*.txt')\n",
    "print(len(files))\n",
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5b4b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ti_sps(path, timezone='Asia/Shanghai'):\n",
    "    df = pd.read_csv(path, names=['user_id', 'tracked_at', 'longitude', 'latitude'])\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude'], crs=\"EPSG:4326\"))\n",
    "    df['tracked_at'] = pd.to_datetime(df['tracked_at'])\n",
    "    df['tracked_at']=df['tracked_at'].dt.tz_localize(timezone)\n",
    "\n",
    "    # Currently using simple parameters\n",
    "    pfs, sps = generate_staypoints(\n",
    "        df,\n",
    "        dist_threshold=100, # Min dist between staypoints, in meters\n",
    "        time_threshold=pd.Timedelta(minutes=10), # Min duration to create a staypoint\n",
    "        gap_threshold=pd.Timedelta(minutes=25), # Max gap time to still mark something as a staypoint\n",
    "        include_last=True, # Makes sure we include the last one if the user ends there\n",
    "    )\n",
    "\n",
    "    if len(sps) > 0:\n",
    "        user_id=sps['user_id'].iloc[0]\n",
    "        sps.to_csv('t-drive_sps/user_'+str(user_id)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34291b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    get_ti_sps(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead21923",
   "metadata": {},
   "source": [
    "Generate trajectories with dropouts and staypoints based on these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fbd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to create on average 8 dropouts. Thus, probability is 8 / len(df). This number is variable\n",
    "def get_dirty_ti_sps(path, avg_num_dropouts=8):\n",
    "    df = pd.read_csv(path, names=['user_id', 'tracked_at', 'longitude', 'latitude'])\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    \n",
    "    df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude'], crs=\"EPSG:4326\"))\n",
    "    df['tracked_at'] = pd.to_datetime(df['tracked_at'])\n",
    "    df['tracked_at']=df['tracked_at'].dt.tz_localize(timezone)\n",
    "    \n",
    "    # Create on average 8 dropouts\n",
    "    dropoutlength = pd.Timedelta(minutes=15) # Can also change dropout time if desired\n",
    "    dropouts = []\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        if random.random() > avg_num_dropouts / len(df):\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        j = i\n",
    "        while j < len(df) and (df['tracked_at'].iloc[j] - df['tracked_at'].iloc[i]) < dropoutlength:\n",
    "            j += 1\n",
    "        \n",
    "        dropouts.append([i, j])\n",
    "\n",
    "        i = j\n",
    "    \n",
    "    all_dropouts = []\n",
    "    for dropout in dropouts:\n",
    "        all_dropouts.extend(list(range(dropout[0], dropout[1])))\n",
    "    \n",
    "    # Write indices of dropouts to a text file\n",
    "    with open('t-drive_dropout_indices/user_'+str(df['user_id'].iloc[0])+'.txt', 'w') as f:\n",
    "        for line in all_dropouts:\n",
    "            f.write(f\"{line}\\n\")\n",
    "\n",
    "    # Create a list of start times we dropped for that agent\n",
    "    lines = [df['tracked_at'].iloc[x[0]] for x in dropouts]\n",
    "    with open('t-drive_dropouts/user_'+str(df['user_id'].iloc[0])+'.txt', 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(f\"{line}\\n\")\n",
    "\n",
    "    df = df.drop(all_dropouts).reset_index(drop=True)\n",
    "\n",
    "    # We should make this check again after adding dropouts\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "\n",
    "    # Rerun trackintel on the trajectory with dropouts\n",
    "    pfs, sps = generate_staypoints(\n",
    "        df,\n",
    "        dist_threshold=100, # Min dist between staypoints, in meters\n",
    "        time_threshold=pd.Timedelta(minutes=10), # Min duration to create a staypoint\n",
    "        gap_threshold=pd.Timedelta(minutes=25), # Max gap time to still mark something as a staypoint\n",
    "        include_last=True, # Makes sure we include the last one if the user ends there\n",
    "    )\n",
    "\n",
    "    # Write to file\n",
    "    if len(sps) > 0:\n",
    "        user_id=sps['user_id'].iloc[0]\n",
    "        sps.to_csv('t-drive_noisy_sps/user_'+str(user_id)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    get_dirty_ti_sps(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b2abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a flag for whether the staypoint is spurious\n",
    "def add_is_spurious(path):\n",
    "    noisy_sps = ti.read_staypoints_csv(path, index_col=None, geom_col='geometry')\n",
    "    user_id = noisy_sps['user_id'].iloc[0]\n",
    "\n",
    "    with open(\"t-drive_dropouts/user_\"+str(user_id)+\".txt\", \"r\") as file:\n",
    "        dropouts = [line.strip() for line in file]\n",
    "    dropouts = pd.Series(dropouts)\n",
    "    dropouts = pd.to_datetime(dropouts)\n",
    "\n",
    "    noisy_sps['is_spurious'] = False\n",
    "    for i in dropouts:\n",
    "        abs_diff = abs(noisy_sps['started_at'] - i)\n",
    "        abs_diff = abs_diff <= diff_threshold\n",
    "        noisy_sps['is_spurious'] = noisy_sps['is_spurious'] | abs_diff\n",
    "    \n",
    "    noisy_sps.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a9f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noised_files = glob.glob('t-drive_noisy_sps/*.csv')\n",
    "for nf in noised_files:\n",
    "    add_is_spurious(nf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b3603",
   "metadata": {},
   "source": [
    "Now apply filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(agent_id):\n",
    "    df = pd.read_csv(data_path + str(agent_id) + '.txt', names=['user_id', 'tracked_at', 'longitude', 'latitude'])\n",
    "    df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude'], crs=\"EPSG:4326\"))\n",
    "    df['tracked_at'] = pd.to_datetime(df['tracked_at'])\n",
    "    df['tracked_at']=df['tracked_at'].dt.tz_localize(timezone)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_noisy_user(agent_id):\n",
    "    df = pd.read_csv(data_path + str(agent_id) + '.txt', names=['user_id', 'tracked_at', 'longitude', 'latitude'])\n",
    "    df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df['longitude'], df['latitude'], crs=\"EPSG:4326\"))\n",
    "    df['tracked_at'] = pd.to_datetime(df['tracked_at'])\n",
    "    df['tracked_at']=df['tracked_at'].dt.tz_localize(timezone)\n",
    "\n",
    "    with open('t-drive_dropout_indices/user_'+str(agent_id)+'.txt') as file:\n",
    "        all_dropouts = [int(line.strip()) for line in file]\n",
    "    \n",
    "    df = df.drop(all_dropouts).reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecdecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dropouts(agent_id):\n",
    "\n",
    "    # Identify dropouts over dropout threshold\n",
    "    traj = get_noisy_user(agent_id)\n",
    "    traj['t_delta'] = traj['tracked_at'].diff(1)\n",
    "    traj['t_delta'] = traj['t_delta'].shift(-1)\n",
    "\n",
    "    dropouts = traj[traj['t_delta'] >= dropout_threshold].reset_index(drop=True)\n",
    "    timezone = 'UTC+08:00'\n",
    "    dropouts['tracked_at']=dropouts['tracked_at'].dt.tz_convert(timezone)\n",
    "\n",
    "    noisy_sps = ti.read_staypoints_csv('t-drive_noisy_sps/user_'+str(agent_id)+'.csv', index_col=None, geom_col='geometry')\n",
    "\n",
    "    # This function call identifies the spurious staypoints\n",
    "    merged = pd.merge_asof(\n",
    "        noisy_sps,\n",
    "        dropouts,\n",
    "        left_on=\"started_at\",\n",
    "        right_on=\"tracked_at\",\n",
    "        tolerance=diff_threshold,\n",
    "        direction=\"forward\"\n",
    "    )\n",
    "\n",
    "    # And here we remove these staypoints\n",
    "    indices_to_drop = noisy_sps.index[merged[\"tracked_at\"].notna()]\n",
    "    non_dropout_sps = noisy_sps.drop(indices_to_drop).reset_index(drop=True)\n",
    "\n",
    "    file_path = 't-drive_sps/user_'+str(agent_id)+'.csv'\n",
    "    if os.path.exists(file_path):\n",
    "        sps = ti.read_staypoints_csv(file_path, index_col=None, geom_col='geometry')\n",
    "    else:\n",
    "        sps = pd.DataFrame() # Should just be able to create an empty df I think\n",
    "\n",
    "    # We return:    Length of original staypoints, \n",
    "    #               length of noised staypoints, \n",
    "    #               length of spurious noised staypoints,\n",
    "    #               length of filtered staypoints\n",
    "    #               length of filtered spurious staypoints\n",
    "    \n",
    "    to_return = [agent_id,\n",
    "                 len(sps), \n",
    "                 len(noisy_sps), \n",
    "                 len(noisy_sps[noisy_sps['is_spurious'] == True]), \n",
    "                 len(non_dropout_sps), \n",
    "                 len(non_dropout_sps[non_dropout_sps['is_spurious'] == True])]\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c37198",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca677e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['user_id', 'num_sps', 'num_noised_sps', 'num_spurious_sps', 'num_filtered_sps', 'num_spurious_filtered_sps'])\n",
    "\n",
    "users = glob.glob('t-drive_noisy_sps/*.csv')\n",
    "users = [int(user[user.index('user') + 5 : user.index('.')]) for user in users]\n",
    "\n",
    "for user in users:\n",
    "    results.loc[len(results)] = filter_dropouts(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ef561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can specify an output location\n",
    "results.to_csv('t-drive_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t-drive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
